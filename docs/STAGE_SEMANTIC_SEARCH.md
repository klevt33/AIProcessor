# SEMANTIC_SEARCH Stage (Implementation Facts)

This document describes the **SEMANTIC_SEARCH** stage exactly as implemented in this repository.

For overall pipeline context and stage ordering, see `docs/SOLUTION_OVERVIEW.md`.

**Primary implementation references**
- Stage orchestration: `ai_stages.py` → `AIStages.check_semantic_match(...)`
- Matching logic: `semantic_matching.py` → `semantic_match_by_description(...)` and helpers
- Azure AI Search client wrapper: `azure_search_utils.py` → `AzureSearchUtils.search(...)`
- Stage routing and order: `special_cases.yaml` (`CASES.CASE_0.STAGES`)
- Stage thresholds (used for next-stage routing): `thresholds.yaml`
- Stage configuration (weights/thresholds for semantic search): `confidences.yaml` → `SEMANTIC_SEARCH.SEMANTIC_SEARCH`

---

## 1. PURPOSE & ROLE

### Purpose in the pipeline
- The SEMANTIC_SEARCH stage performs a **vector-based search** against an Azure AI Search index to find **similar catalog items** based on the invoice line description.
- From the retrieved similar items, it computes **confidence-scored** candidate values for:
  - **Manufacturer name**
  - **UNSPSC**

### Position in the default pipeline
In `special_cases.yaml` (`CASE_0`, the default pipeline), stage order is:
1. `CLASSIFICATION`
2. `SEMANTIC_SEARCH`
3. `COMPLETE_MATCH`
4. `CONTEXT_VALIDATOR`
5. `FINETUNED_LLM`
6. `EXTRACTION_WITH_LLM_AND_WEBSEARCH`

### Three roles implemented
The codebase uses SEMANTIC_SEARCH outputs in three distinct ways:

1) **Data enrichment (manufacturer / UNSPSC)**
- `AIStages.check_semantic_match(...)` calls `semantic_match_by_description(...)` and writes returned values into the stage output (`stage_details.details`).
- These values can later be copied forward into downstream stage outputs by consolidation/enrichment logic (see `StageUtils.consolidate_all_fields_confidences(...)` in `ai_stages.py`).

2) **Confidence boosting**
- `StageUtils._apply_confidence_boosting(...)` can raise a later stage’s confidence score for a field when:
  - the later stage produced the field,
  - a prior stage (including SEMANTIC_SEARCH) produced the same field value,
  - the values match, and
  - the prior stage confidence is higher.

3) **Context creation for the fine-tuned LLM**
- `semantic_match_by_description(...)` returns a small list of high-similarity raw search items.
- `AIStages.check_semantic_match(...)` stores these raw items into `ai_engine_cache.semantic_search_results`.
- `execute_hardened_llm_request(...)` (in `ai_utils.py`) uses those cached items as **few-shot examples** when constructing the prompt input for the `FINETUNED_LLM` stage.

### What it does NOT do
- The SEMANTIC_SEARCH stage **does not produce a part number in its stage output**.
  - The stage output written by `AIStages._process_semantic_match_result(...)` includes only manufacturer name and/or UNSPSC (plus confidence and metadata).
  - The stage may still **retrieve** `MfrPartNum` from Azure AI Search as part of the raw results list used for LLM context, but that part number is **not** emitted as a stage output field.

---

## 2. KEY CONCEPTS

### Vector embeddings
- The stage represents text (the invoice item description) as a numeric vector.
- Embeddings are generated by `LLM.get_embeddings(...)` (in `llm.py`) using `AzureOpenAIEmbeddings.embed_documents(...)`.
- Embedding dimensionality is configured by `Config.AOAI_EMBEDDING_DIMENSIONS` (loaded in `config.py`).

### Semantic similarity
- SEMANTIC_SEARCH uses Azure AI Search vector search and reads the returned similarity as `@search.score`.
- Configuration values in `confidences.yaml` treat similarity thresholds as **0.0–1.0** (see comments under `similarity_threshold` and `min_example_similarity`).
- Internally, confidence computations in `semantic_matching.py` multiply `@search.score` by 100 when converting to a 0–100 scale.

### Product indexing (Azure AI Search index)
The index schema used for semantic search is defined in `indexer/semantic_search_indexer.py` in `Indexer.create_search_index()`.

Key fields referenced by SEMANTIC_SEARCH:
- `ItemDescription_vector` (vector field)
- `ItemDescription` (text)
- `ItemID` (used for deduplication)
- `MfrName`
- `UNSPSC`
- `MfrPartNum` (retrieved for raw context examples)

### Distance / similarity metric
- The indexer creates a vector search configuration using HNSW with `metric="cosine"` (`Indexer.create_search_index()` → `AzureSearchUtils.create_vector_search_config(metric="cosine")`).

---

## 3. INPUT & OUTPUT

### Input
At runtime, SEMANTIC_SEARCH is invoked by `AIStages.check_semantic_match(...)` with:
- `ivce_dtl.ITM_LDSC`: the raw invoice item description string
- `sdp`: optional database connection used for manufacturer name cleaning (see below)
- `ai_engine_cache`: per-invoice-line cache object

Within the stage:
- The description is cleaned using `clean_description(...)` (from `utils.py`).
- An embedding is generated from the cleaned description.

### Output (stage result)
`AIStages.check_semantic_match(...)` returns:
- `stage_details`: a `StageDetails` object with
  - `stage_name = StageNames.SEMANTIC_SEARCH`
  - `sub_stage_name = SubStageNames.SEMANTIC_SEARCH`
  - `status` set to `success` or `error`
  - `details` containing only non-empty values after cleanup
- `ai_engine_cache`: updated with:
  - `description_embedding`
  - optionally `semantic_search_results` (raw items for LLM context)

When a semantic match summary is produced, `stage_details.details` is populated by `AIStages._process_semantic_match_result(...)` with:
- `manufacturer_name` (from `match_result["MfrName"]`)
- `unspsc` (from `match_result["UNSPSC"]`)
- `confidence_score` (a dict that may contain):
  - `manufacturer_name`: from `match_result["ManufacturerNameConfidenceScore"]`
  - `unspsc`: from `match_result["UNSPSCConfidenceScore"]`
- `description`: the cleaned invoice description
- `is_mfr_clean_flag`: whether manufacturer mapping was applied

Additional metadata:
- `is_verified_flag` is set to `False`
- `end_time` is set to the current timestamp (`get_current_datetime_cst()`)

### Output NOT produced
- `part_number` is not written into `stage_details.details` by SEMANTIC_SEARCH.

### Raw search results (for LLM context)
- `semantic_match_by_description(...)` also returns a list of up to 3 dictionaries (see `_filter_results_for_rag_context(...)`).
- These dictionaries are derived from Azure AI Search results and may include:
  - `ItemDescription`, `MfrName`, `UNSPSC`, `MfrPartNum`, `ItemID`, `DescriptionID`, and `@search.score` (and any selected fields).
- `AIStages.check_semantic_match(...)` stores this list in `ai_engine_cache.semantic_search_results`.

---

## 4. CONFIGURATION PARAMETERS (confidences.yaml)

Configuration is loaded by `semantic_matching.get_config()` from `LocalFiles.CONFIDENCES_FILE` and read from:

`confidences.yaml` → `SEMANTIC_SEARCH` → `SEMANTIC_SEARCH`

### SEARCH
- `SEARCH.similarity_threshold` (float; documented as 0–1)
  - Used to filter Azure AI Search results in `_fetch_distinct_items(...)`:
    - Only rows with `@search.score >= similarity_threshold` are kept.
- `SEARCH.top_results` (int)
  - Target number of **distinct** results (by `ItemID`) returned from `_fetch_distinct_items(...)`.
  - Passed as `top_distinct_results`.
- `SEARCH.max_results` (int)
  - Initial per-iteration fetch size used in `_fetch_distinct_items(...)`.
  - The code may fetch more than `max_results` in later iterations (`max(initial_fetch_size, num_needed * 2)`).

### WEIGHTS
- `WEIGHTS.mid_point` (float)
  - Used in `_calculate_weights(...)` as the midpoint of the exponential weighting curve.
- `WEIGHTS.exp_factor` (float)
  - Used in `_calculate_weights(...)` as the exponent multiplier controlling curve steepness.

**Weight formula (implemented)**
- For each row: `weight = exp(exp_factor * (@search.score - mid_point))`

### CONFIDENCE
- `CONFIDENCE.single_match_factor` (float; comment indicates 0–1)
  - Applied only when semantic search yields exactly one distinct result.
  - Multiplies the computed confidence score for manufacturer and/or UNSPSC.
- `CONFIDENCE.min_confidence_threshold` (float; comment indicates 0–100)
  - Manufacturer/UNSPSC summary values are only returned if their computed confidence is **greater than** this threshold.
- `CONFIDENCE.single_match_similarity_threshold` (float; comment indicates 0–100)
  - Only applied in the single-distinct-result case.
  - If `@search.score * 100` is below this threshold, the function returns no summary result.

### UNSPSC
- `UNSPSC.level_thresholds` (list[int])
  - Iterated in order by `_select_best_unspsc_variant(...)`.
  - For each threshold value, the code tries to choose:
    1) the best commodity-level (8-digit) variant meeting the threshold,
    2) else class-level variant meeting the threshold (with a comparison against commodity),
    3) else family-level variant meeting the threshold (with a comparison against higher levels).
- `UNSPSC.generic_delta_percentage` (number)
  - Used when comparing a more generic UNSPSC (family/class) to a more specific UNSPSC.
  - A more generic code is selected only if it is “significantly better” than the best more-specific code according to the implemented delta checks.

**UNSPSC hierarchy variants (implemented)**
For an 8+ character UNSPSC string:
- commodity (level 3): original code
- class (level 2): first 6 digits + `"00"`
- family (level 1): first 4 digits + `"0000"`

### RAG_CONTEXT
- `RAG_CONTEXT.min_example_similarity` (float; documented as 0.0–1.0)
  - Used by `_filter_results_for_rag_context(...)`.
  - Only results with `@search.score >= min_example_similarity` are included as raw examples for the fine-tuned LLM.

---

## 5. BUSINESS LOGIC — IMPLEMENTATION FACTS ONLY

### Search execution
Implemented in `semantic_matching.semantic_match_by_description(...)` and `_fetch_distinct_items(...)`:

1) **Embedding**
- If `description` is a string, `_get_embedding(...)` requires an `LLM` instance and calls `llm.get_embeddings([description])[0]`.
- In the pipeline, `AIStages.check_semantic_match(...)` passes an embedding vector (not a string), so `_get_embedding(...)` returns it unchanged.

2) **Vector query construction**
- `_fetch_distinct_items(...)` builds:
  - `vector = embedding`
  - `fields = "ItemDescription_vector"`
  - `k_nearest_neighbors = num_to_fetch`

3) **Filtering**
- `_fetch_distinct_items(...)` uses a base OData filter:
  - `"UNSPSC ne null"`
- If any `ItemID`s have already been collected, the filter is extended with:
  - `ItemID ne <id>` joined by `and`

4) **Distinct-by-item behavior**
- `_fetch_distinct_items(...)` collects results until it has `top_distinct_results` unique `ItemID`s.
- If multiple hits for the same `ItemID` exist, the code keeps the first (highest-score) hit encountered after sorting by `@search.score` descending.

5) **Selected fields**
`semantic_match_by_description(...)` requests these fields from the index:
- `ItemID`, `DescriptionID`, `MfrName`, `UNSPSC`, `ItemDescription`, `MfrPartNum`

### Result ranking and weighting
- Results are sorted by `@search.score` descending in `_fetch_distinct_items(...)`.
- `_calculate_weights(...)` adds a `weight` column using the exponential weight formula described in Section 4.

### Manufacturer confidence scoring (summary output)
Implemented in `_process_manufacturer_with_weights(...)`:

- Rows are grouped by `MfrName`.
- For each manufacturer:
  - `group_weight = sum(weight for rows in that manufacturer group)`
  - `total_weight = sum(weight for all rows)`
  - `max_search_score = max(@search.score for rows in that manufacturer group)`
  - `confidence = max_search_score * (group_weight / total_weight) * 100`
- If the overall search yielded a single distinct result (`len(results) == 1`), confidence is multiplied by `single_match_factor`.
- The selected manufacturer is the one with the maximum computed confidence.
- The manufacturer is returned only if `confidence > min_confidence_threshold`.
- The stage also returns `IsMfrClean`:
  - initialized as `False`
  - set to `True` if any manufacturer mapping replacement occurs when `sdp` is provided.

### UNSPSC confidence scoring (summary output)
Implemented in `_process_unspsc_with_weights(...)`:

- The code computes confidences for multiple UNSPSC **variants** (commodity/class/family).
- For each variant:
  - Determine matching rows based on prefix rules (exact match for commodity; prefix match for class/family).
  - Compute confidence using the same formula shape:
    - `confidence = max_search_score * (variant_weight / total_weight) * 100`
- The selection of the “best” UNSPSC uses `_select_best_unspsc_variant(...)` with:
  - configured `level_thresholds`
  - `generic_delta_percentage`
- Single-match adjustment:
  - if only one distinct result exists, the chosen UNSPSC confidence is multiplied by `single_match_factor`.
- The UNSPSC is returned only if `confidence > min_confidence_threshold`.

### Output determination and cleanup
- `semantic_match_by_description(...)` returns:
  - `result_data`: a dict that may include `MfrName`, `ManufacturerNameConfidenceScore`, `UNSPSC`, `UNSPSCConfidenceScore`, `IsMfrClean`
  - `top_n_items`: a list of up to 3 raw items for context
- `AIStages._process_semantic_match_result(...)`:
  - uses `clean_dictionary(...)` to drop empty / null / NaN values
  - builds `confidence_score` dict with keys `manufacturer_name` and `unspsc` when present

### Context creation for the fine-tuned LLM
Implemented across:
- `semantic_matching._filter_results_for_rag_context(...)`
- `AIStages.check_semantic_match(...)` (caching)
- `ai_utils.build_context_augmented_description(...)`

Facts from implementation:
- Up to 3 examples are selected for context.
- Examples are deduplicated by `(MfrName.upper(), UNSPSC)`.
- Examples are formatted as lines of:
  - `'ItemDescription' -> {'ManufacturerName': <MfrName>, 'PartNumber': <MfrPartNum>, 'UNSPSC': <UNSPSC>}`
- `execute_hardened_llm_request(...)` can try up to 3 prompt strategies; for attempts 1 and 2 it includes examples if present, and for attempt 3 it omits examples.

---

## 6. PIPELINE INTEGRATION

### Position and routing
- Stage order for default processing is defined in `special_cases.yaml` (Section 1).
- The orchestrator for extraction stages is `AIEngine` (see `ai_engine.py`).
- SEMANTIC_SEARCH is configured in `AIEngine.prepare_extraction_engine()` with:
  - `stage_number = 4`
  - `sub_stage_code = "2.0"`
  - fields consolidated: manufacturer name + UNSPSC

### Input source
- The stage uses the invoice detail description (`ivce_dtl.ITM_LDSC`) after cleaning.
- It also uses `sdp` if provided for manufacturer mapping.

### Output destination
- Stage outputs are recorded into `StageResults` by the engine.
- Raw semantic search results (up to 3) are cached in `ai_engine_cache.semantic_search_results` and passed into the `FINETUNED_LLM` stage.

### Success criteria (routing)
The decision to proceed to the next stage is driven by:
- `StageUtils.check_if_next_stage_required(...)` (in `ai_stages.py`)
- Thresholds loaded from `thresholds.yaml`

**Rule (implemented)**
- For each field in `ivce_dtl.fields`, the stage must:
  - include the field in `stage_details.details`, and
  - include a confidence score for that field in `stage_details.details["confidence_score"]`, and
  - meet or exceed the configured threshold for the current stage/sub-stage.
- If any required field fails, the next stage is required.

### Failure handling
- If the invoice description is empty after cleaning, `AIStages.check_semantic_match(...)` returns `status = error` with a message.
- If no qualifying search results are returned, the stage returns `status = success` with the message `"No semantic match found"`.

---

## 7. DATA QUALITY & VALIDATION

### Input validation
- Description must be non-empty after `clean_description(...)`.
- If it is empty, the stage stops with `status = error`.

### Search result validation / filtering
- Results must have `@search.score >= SEARCH.similarity_threshold`.
- Results are filtered to `UNSPSC ne null` via Azure Search OData filter.
- Manufacturer/UNSPSC processing skips if the relevant column is missing or all values are NaN.

### Output validation
- The stage applies `clean_dictionary(...)` to remove empty/null/NaN values before returning details.
- Confidence values returned in the stage output are rounded to integers (`round(confidence_score)`).

### Error handling
- Embedding generation errors are wrapped as `InvoiceProcessingError` and handled by `AIStages.check_semantic_match(...)`.
- Manufacturer mapping errors are logged and do not stop matching; the stage proceeds with original manufacturer names.

### Logging
- The stage logs debug messages for:
  - embedding generation
  - performing the search
  - caching raw items for LLM context
  - match results / no-match outcomes
- Errors are logged with stack traces when exceptions occur.

---

## 8. OPERATIONAL DETAILS (FACTS ONLY)

### External dependencies
- Azure AI Search (vector query via `azure.search.documents` SDK)
- Azure OpenAI embeddings (via `AzureOpenAIEmbeddings` in `llm.py`)

### Parallelization / threading
- SEMANTIC_SEARCH itself does not create threads.
- Invoice processing can run in parallel at the worker level:
  - `worker.py` creates a `ThreadPoolExecutor(max_workers=self.MAX_WORKERS)`.

### Batch processing
- The semantic matching functions operate on a **single invoice line description at a time**.

### Caching
- Per-invoice-line cache fields used:
  - `ai_engine_cache.description_embedding`
  - `ai_engine_cache.semantic_search_results`
- No cross-request or persistent cache is implemented in this stage.

### Resource requirements
- The repository does not define explicit CPU, memory, or storage sizing requirements for SEMANTIC_SEARCH.

---

## 9. CONCEPTUAL EXAMPLES (LOGIC-ONLY)

These examples illustrate the implemented calculations using explicit inputs.

### Example 1 — Manufacturer confidence from multiple results
**Inputs**
- Distinct Azure AI Search results (already filtered by `similarity_threshold`):
  - Row A: `MfrName = "ACME"`, `@search.score = 0.90`
  - Row B: `MfrName = "ACME"`, `@search.score = 0.85`
  - Row C: `MfrName = "CONTOSO"`, `@search.score = 0.88`
- `mid_point = 0.55`, `exp_factor = 10`

**Processing (implemented)**
1) Compute weights per row:
   - `weight = exp(10 * (score - 0.55))`
2) Group by manufacturer and compute:
   - `confidence = max_search_score * (group_weight / total_weight) * 100`
3) Select the manufacturer with maximum confidence.
4) Return it only if `confidence > min_confidence_threshold`.

**Outputs (shape)**
- If ACME has the highest computed confidence and exceeds the threshold:
  - `manufacturer_name = "ACME"`
  - `confidence_score.manufacturer_name = <rounded int>`

### Example 2 — UNSPSC variant selection (commodity vs class)
**Inputs**
- Search results include UNSPSC values:
  - `"44120000"` (family/class-like form)
  - `"44121604"` (8-digit commodity)
- Variant confidences are computed for:
  - commodity level (exact 8-digit matches)
  - class level (first 6 digits)
  - family level (first 4 digits)
- `level_thresholds = [90, 80, 70, 60]`
- `generic_delta_percentage = 10`

**Processing (implemented)**
- `_select_best_unspsc_variant(...)` iterates thresholds in order.
- At each threshold it attempts to pick the best commodity meeting the threshold.
- If it picks a class variant, it compares it to the best commodity; if the class confidence is not sufficiently higher per the delta rule, it returns the commodity instead.

**Outputs (shape)**
- `unspsc = <selected UNSPSC variant string>`
- `confidence_score.unspsc = <rounded int>`

### Example 3 — Few-shot example construction for FINETUNED_LLM
**Inputs**
- `ai_engine_cache.semantic_search_results` contains a list of dictionaries, each with (at minimum):
  - `ItemDescription`, `MfrName`, `MfrPartNum`, `UNSPSC`

**Processing (implemented)**
- `build_context_augmented_description(...)` formats up to 3 examples as:
  - `'ItemDescription' -> {'ManufacturerName': ..., 'PartNumber': ..., 'UNSPSC': ...}`
- These examples are prepended to the fine-tuned LLM input on attempt 1 and attempt 2.

**Outputs (shape)**
- A single prompt string passed into the fine-tuned LLM that includes:
  - manufacturer aliases (if provided)
  - examples (if available and attempt < 3)
  - the target invoice description

---

## 10. SPECIAL CASES & EDGE CASES (FROM CODE)

### Empty description
- If `clean_description(ivce_dtl.ITM_LDSC)` returns an empty string, SEMANTIC_SEARCH returns `status = error` and does not call Azure AI Search.

### No qualifying search results
- If `_fetch_distinct_items(...)` returns an empty DataFrame, `semantic_match_by_description(...)` returns empty outputs.
- `AIStages.check_semantic_match(...)` reports `status = success` with message `"No semantic match found"`.

### Single distinct result handling
- If exactly one distinct `ItemID` result is returned:
  - the stage checks `@search.score * 100` against `single_match_similarity_threshold` and returns no summary if the score is below the threshold.
  - if the score passes, computed confidences are multiplied by `single_match_factor`.

### Manufacturer mapping failures
- If `read_manufacturer_data(sdp)` fails or mapping application raises, the stage logs a warning and continues without cleaning.

### UNSPSC formatting issues
- UNSPSC variants are only generated for string values with length >= 8.
- Prefix matching for class/family selection uses string prefix checks.

### Generic pipeline behavior
- `special_cases.yaml` defines `CASE_1` (generic items pipeline) which skips `COMPLETE_MATCH`.
- SEMANTIC_SEARCH itself does not implement a special “generic” branch; it runs the same logic regardless of special case.
